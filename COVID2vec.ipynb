{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word2Vec specificiation\n",
    "- Skip-gram\n",
    "- Negative sampling loss $n = 15$\n",
    "- All words that occured greater than (> or >= ?) 5 times\n",
    "- Normalised chemical formulae\n",
    "\n",
    "They also add phrases to the vocabulary\n",
    "- Minimum phrase count of 10 - phrase needs to appear at least 10 times I think\n",
    "- Score threshold of 5 - not sure \n",
    "- Phrase depth of 2\n",
    "- TODO: explain how this works\n",
    "- 200-d dimensional embeddings\n",
    "- LR of 0.01 decreasing to 0.0001 in 30 epochs\n",
    "- Context window of 8\n",
    "- Subsampling with 10^-4 threshold - subsamples approx 400 most common words\n",
    "\n",
    "To run this without the formula stuff and included phrases, these settings are needed:\n",
    "- keep_formula False\n",
    "- include_extra_phrases False\n",
    "- TODO: find out how to load the data\n",
    "\n",
    "\n",
    "The validation data is kind of different \n",
    "- TODO: create analogies \n",
    "- TODO: how to load analogies\n",
    "- It is not a corpus but analogies \n",
    "- Note that the model weights are the word vectors \n",
    "- They are the features for the words, analogous to the features you get from a pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['The',\n",
       "  'recently',\n",
       "  'introduced',\n",
       "  'continuous',\n",
       "  'Skipgram',\n",
       "  'model',\n",
       "  'is',\n",
       "  'an',\n",
       "  'efficient',\n",
       "  'method',\n",
       "  'for',\n",
       "  'learning',\n",
       "  'highquality',\n",
       "  'distributed',\n",
       "  'vector',\n",
       "  'representations',\n",
       "  'that',\n",
       "  'capture',\n",
       "  'a',\n",
       "  'large',\n",
       "  'number',\n",
       "  'of',\n",
       "  'precise',\n",
       "  'syntactic',\n",
       "  'and',\n",
       "  'semantic',\n",
       "  'word',\n",
       "  'relationships'],\n",
       " ['In',\n",
       "  'this',\n",
       "  'paper',\n",
       "  'we',\n",
       "  'present',\n",
       "  'several',\n",
       "  'extensions',\n",
       "  'that',\n",
       "  'improve',\n",
       "  'both',\n",
       "  'the',\n",
       "  'quality',\n",
       "  'of',\n",
       "  'the',\n",
       "  'vectors',\n",
       "  'and',\n",
       "  'the',\n",
       "  'training',\n",
       "  'speed'],\n",
       " ['By',\n",
       "  'subsampling',\n",
       "  'of',\n",
       "  'the',\n",
       "  'frequent',\n",
       "  'words',\n",
       "  'we',\n",
       "  'obtain',\n",
       "  'significant',\n",
       "  'speedup',\n",
       "  'and',\n",
       "  'also',\n",
       "  'learn',\n",
       "  'more',\n",
       "  'regular',\n",
       "  'word',\n",
       "  'representations'],\n",
       " ['We',\n",
       "  'also',\n",
       "  'describe',\n",
       "  'a',\n",
       "  'simple',\n",
       "  'alternative',\n",
       "  'to',\n",
       "  'the',\n",
       "  'hierarchical',\n",
       "  'softmax',\n",
       "  'called',\n",
       "  'negative',\n",
       "  'sampling'],\n",
       " ['An',\n",
       "  'inherent',\n",
       "  'limitation',\n",
       "  'of',\n",
       "  'word',\n",
       "  'representations',\n",
       "  'is',\n",
       "  'their',\n",
       "  'indifference',\n",
       "  'to',\n",
       "  'word',\n",
       "  'order',\n",
       "  'and',\n",
       "  'their',\n",
       "  'inability',\n",
       "  'to',\n",
       "  'represent',\n",
       "  'idiomatic',\n",
       "  'phrases'],\n",
       " ['For',\n",
       "  'example',\n",
       "  'the',\n",
       "  'meanings',\n",
       "  'of',\n",
       "  'Canada',\n",
       "  'and',\n",
       "  'Air',\n",
       "  'cannot',\n",
       "  'be',\n",
       "  'easily',\n",
       "  'combined',\n",
       "  'to',\n",
       "  'obtain',\n",
       "  'Air',\n",
       "  'Canada'],\n",
       " ['Motivated',\n",
       "  'by',\n",
       "  'this',\n",
       "  'example',\n",
       "  'we',\n",
       "  'present',\n",
       "  'a',\n",
       "  'simple',\n",
       "  'method',\n",
       "  'for',\n",
       "  'finding',\n",
       "  'phrases',\n",
       "  'in',\n",
       "  'text',\n",
       "  'and',\n",
       "  'show',\n",
       "  'that',\n",
       "  'learning',\n",
       "  'good',\n",
       "  'vector',\n",
       "  'representations',\n",
       "  'for',\n",
       "  'millions',\n",
       "  'of',\n",
       "  'phrases',\n",
       "  'is',\n",
       "  'possible']]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"\"\"The recently introduced continuous Skip-gram model is an efficient method for learning high-quality distributed vector representations that capture a large number of precise syntactic and semantic word relationships. In this paper we present several extensions that improve both the quality of the vectors and the training speed. By subsampling of the frequent words we obtain significant speedup and also learn more regular word representations. We also describe a simple alternative to the hierarchical softmax called negative sampling. An inherent limitation of word representations is their indifference to word order and their inability to represent idiomatic phrases. For example, the meanings of \"Canada\" and \"Air\" cannot be easily combined to obtain \"Air Canada\". Motivated by this example, we present a simple method for finding phrases in text, and show that learning good vector representations for millions of phrases is possible.\"\"\"\n",
    "sents = text.split('. ')\n",
    "tokens = [''.join(i for i in s if i not in string.punctuation).split() for s in sents]\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import datapath\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "\n",
    "phrases = Phrases(list(map(tuple, tokens)), min_count=1, threshold=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = Phraser(phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = f[tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['The',\n",
       "  'recently',\n",
       "  'introduced',\n",
       "  'continuous',\n",
       "  'Skipgram',\n",
       "  'model',\n",
       "  'is',\n",
       "  'an',\n",
       "  'efficient',\n",
       "  'method_for',\n",
       "  'learning',\n",
       "  'highquality',\n",
       "  'distributed',\n",
       "  'vector_representations',\n",
       "  'that',\n",
       "  'capture',\n",
       "  'a',\n",
       "  'large',\n",
       "  'number',\n",
       "  'of',\n",
       "  'precise',\n",
       "  'syntactic',\n",
       "  'and',\n",
       "  'semantic',\n",
       "  'word',\n",
       "  'relationships'],\n",
       " ['In',\n",
       "  'this',\n",
       "  'paper',\n",
       "  'we_present',\n",
       "  'several',\n",
       "  'extensions',\n",
       "  'that',\n",
       "  'improve',\n",
       "  'both',\n",
       "  'the',\n",
       "  'quality',\n",
       "  'of_the',\n",
       "  'vectors',\n",
       "  'and',\n",
       "  'the',\n",
       "  'training',\n",
       "  'speed'],\n",
       " ['By',\n",
       "  'subsampling',\n",
       "  'of_the',\n",
       "  'frequent',\n",
       "  'words',\n",
       "  'we',\n",
       "  'obtain',\n",
       "  'significant',\n",
       "  'speedup',\n",
       "  'and',\n",
       "  'also',\n",
       "  'learn',\n",
       "  'more',\n",
       "  'regular',\n",
       "  'word_representations'],\n",
       " ['We',\n",
       "  'also',\n",
       "  'describe',\n",
       "  'a_simple',\n",
       "  'alternative',\n",
       "  'to',\n",
       "  'the',\n",
       "  'hierarchical',\n",
       "  'softmax',\n",
       "  'called',\n",
       "  'negative',\n",
       "  'sampling'],\n",
       " ['An',\n",
       "  'inherent',\n",
       "  'limitation',\n",
       "  'of',\n",
       "  'word_representations',\n",
       "  'is',\n",
       "  'their',\n",
       "  'indifference',\n",
       "  'to',\n",
       "  'word',\n",
       "  'order',\n",
       "  'and',\n",
       "  'their',\n",
       "  'inability',\n",
       "  'to',\n",
       "  'represent',\n",
       "  'idiomatic',\n",
       "  'phrases'],\n",
       " ['For',\n",
       "  'example',\n",
       "  'the',\n",
       "  'meanings',\n",
       "  'of',\n",
       "  'Canada',\n",
       "  'and',\n",
       "  'Air',\n",
       "  'cannot',\n",
       "  'be',\n",
       "  'easily',\n",
       "  'combined',\n",
       "  'to',\n",
       "  'obtain',\n",
       "  'Air',\n",
       "  'Canada'],\n",
       " ['Motivated',\n",
       "  'by',\n",
       "  'this',\n",
       "  'example',\n",
       "  'we_present',\n",
       "  'a_simple',\n",
       "  'method_for',\n",
       "  'finding',\n",
       "  'phrases',\n",
       "  'in',\n",
       "  'text',\n",
       "  'and',\n",
       "  'show',\n",
       "  'that',\n",
       "  'learning',\n",
       "  'good',\n",
       "  'vector_representations',\n",
       "  'for',\n",
       "  'millions',\n",
       "  'of',\n",
       "  'phrases',\n",
       "  'is',\n",
       "  'possible']]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37venv",
   "language": "python",
   "name": "py37venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
